# ğŸŒŸ Machine Learning Project

Welcome to the **Machine Learning Project**! This project is a collection of machine learning algorithms implemented in Python from scratch. Currently, it includes linear regression and logistic regression models, and it is designed to be expanded with more algorithms in the future.

## ğŸ“š Table of Contents
- [ğŸŒŸ Introduction](#\ğŸŒŸ-introduction)
- [ğŸ“ˆ Linear Regression](#\ğŸ“ˆ-linear-regression)
  - [ğŸ“Š Generating the Training Set](#\ğŸ“Š-generating-the-training-set)
  - [ğŸ§  Training the Model](#\ğŸ§ -training-the-model)
- [ğŸš¦ Logistic Regression](#\ğŸš¦-logistic-regression)
  - [ğŸ“Š Generating the Training Set](#\ğŸ“Š-generating-the-training-set-1)
  - [ğŸ§  Training the Model](#\ğŸ§ -training-the-model-1)
- [ğŸš€ Future Work](#\ğŸš€-future-work)

## ğŸŒŸ Introduction
This project provides implementations of various machine learning algorithms from scratch. It serves as an educational tool and as a foundation for more complex projects.

## ğŸ“ˆ Linear Regression
Linear regression is a simple yet powerful algorithm for predicting a continuous target variable based on one or more input features. The goal is to find the best-fitting straight line through the data points that minimizes the sum of the squared differences between the observed values and the values predicted by the line.

### ğŸ“Š Generating the Training Set
The training set for the linear regression model is generated using the `linear-regression/generate_training_set.py` script. This script creates a dataset with a specified number of features, weights, bias, and noise level.

### ğŸ§  Training the Model
The project includes implementations for both single and multiple feature linear regression:
- **Single Feature**: `LR_1Feature.ipynb`
- **Multiple Features**: `LR_MultipleFeature.ipynb`

Both notebooks utilize gradient descent with features such as z-score normalization and early convergence detection.

## ğŸš¦ Logistic Regression
Logistic regression is used for binary classification. It estimates probabilities using the logistic function, and the decision boundary is computed based on these probabilities.

### ğŸ“Š Generating the Training Set
The logistic regression training set is generated using the `logistic-regression/generate_training_set.py` script. This script creates random features and binary labels for testing the logistic regression code.

### ğŸ§  Training the Model
The logistic regression model is implemented in the `logistic-regression/LG_MultiFeature.ipynb` notebook. The notebook includes:
- Reading and normalizing the training data
- Computing predictions using the logistic function
- Optimizing parameters via gradient descent
- Printing and plotting the decision boundary (for 2 features)

## ğŸš€ Future Work
The project is designed to be expanded with additional machine learning algorithms. Some potential additions include:
- Polynomial Regression
- Neural Networks
- Decision Trees
- Random Forests
- Boosted Trees
- Unsupervised Learning
- Reinforcement Learning